{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shpotes/stylegan2/blob/master/notebooks/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A_jmZL4vQnk"
   },
   "source": [
    "### Setup\n",
    "Stylegan2 está escrito en tensorflow 1, razon por la cual se debe cambiar el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xlj8b5d8vLHj",
    "outputId": "a6462ec7-8912-497e-bc08-a08295f6a24c"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3j_YVkyvgia"
   },
   "source": [
    "Tambien es necesario descargar mi fork de stylegan2 y testear la GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmuG0LGJvZRa",
    "outputId": "5dae2f17-18ea-45f0-a0e5-28c4d6b2606e"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/shpotes/stylegan2\n",
    "%cd stylegan2\n",
    "!nvcc test_nvcc.cu -o test_nvcc -run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBpDKWBWvyAF"
   },
   "outputs": [],
   "source": [
    "!mkdir aligned\n",
    "!mkdir generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbCa6qfPwFVO"
   },
   "source": [
    "### Cargar tus propias imagenes\n",
    "Se debe cargar la imagen a la cual se le desea cambiar el estilo en `raw/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7NpWFOoxCN-"
   },
   "source": [
    "### Alineo de las imagenes.\n",
    "Stylegan2 fue entrenado con FFHQ, un dataset de caras humanas. Para construirlo, se descagaron fotos de Flickr y automaticamente alineadas siguiendo el preocedimiento descrito en [[Kazemi & Sullivan, 2014]](https://ieeexplore.ieee.org/document/6909637). En consecuencia, si se desea aplicar efectivamente stylegan2 es necesrio realizar dicho preprocesamiento sobre las imagenes en consideracion.\n",
    "\n",
    "La implementacion está basada en la realizada por [@rolux](https://github.com/rolux/stylegan2encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqmax3Txw8qM"
   },
   "outputs": [],
   "source": [
    "!python align_images.py raw aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcKRsSaTyRT-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import textwrap\n",
    "import os\n",
    "\n",
    "def display_images(\n",
    "    images: [Image.Image], \n",
    "    columns=5, width=20, height=8, max_images=15, \n",
    "    label_wrap_length=50, label_font_size=8):\n",
    "\n",
    "    if not images:\n",
    "        print(\"No images to display.\")\n",
    "        return \n",
    "\n",
    "    if len(images) > max_images:\n",
    "        print(f\"Showing {max_images} images of {len(images)}:\")\n",
    "        images=images[0:max_images]\n",
    "\n",
    "    height = max(height, int(len(images)/columns) * height)\n",
    "    plt.figure(figsize=(width, height))\n",
    "    for i, image in enumerate(images):\n",
    "\n",
    "        plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "        if hasattr(image, 'filename'):\n",
    "            title=image.filename\n",
    "            if title.endswith(\"/\"): title = title[0:-1]\n",
    "            title=os.path.basename(title)\n",
    "            title=textwrap.wrap(title, label_wrap_length)\n",
    "            title=\"\\n\".join(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "QmrPRIh7zqoI",
    "outputId": "0a021549-1822-44cd-acd0-894e1fd0b2d1"
   },
   "outputs": [],
   "source": [
    "display_images(\n",
    "    [Image.open('alejo.jpeg'), Image.open('aligned/alejo_01.jpeg.png')],\n",
    "    columns=2,\n",
    "    width=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdtLdAKz0u25"
   },
   "source": [
    "### Stylegan magic\n",
    "Es el momento de crear. Debido a que stylgan es una arquitectura generativa, esta no recibe imagenes de entrada. En consecuencia, se debe realizar un esfuerzo adicional para ingresar la imagen data. Antes de entrar en detalle, haré una breve introduccion a stylegan. \n",
    "\n",
    "La inestabilidad asociada al entrenamiento de las GANs hace complicado lograr escalarlas adecuadamente. [Karras et al [2018]](https://arxiv.org/abs/1710.10196v3) solucionan este problema en proGAN aumento progresivamente el tamaño del generador y discriminador, así el modelo empieza jugando con imagenes de baja resolucion. Durante el entrenamiento, al modelo se le agregan capaz que son tuneadas adecuadamente para aumentar progresivamente la resolucion de la imagen. Sin embargo, el generador resultante, al igual que el de la mayoría de GANs ofrece muy poco control de las imagenes generadas.\n",
    "Para resolver esto, stylegan propone lo siguiente: En lugar de samplear la entrada de la GAN directamente de un espacio latente $Z$ (usualmente se sample ruido gaussiano), se aprende una entrada constante a partir de la cual se empiza a sintetizar la imagen. El vector latentt $z\\in Z$ es mapeado a un espacio $W$ por una red neuronal. El proposito de esta red conocida como mapping network es precisamente aprender un espacio en el cual sea posible controlar mas facilmente la generacion. El resultado final observado, es un espacio $W$ en el cual, movimientos en este estan asociados a cambios semanticos en la imagen. \n",
    "el vector $w$ es agregado en los diferentes niveles de la imagen via adaptive instance normalization. \n",
    "\n",
    "Ok dude, pero.... ¿Como ingreso una imagen? [Dosovitskiy et al [2016]](https://arxiv.org/abs/1602.02644) propusieron un algoritmo eficiente para embeber imagenes en StyleGAN. Desde hace tiempo, es bien sabido en computer vision que el espacio de los pixeles es malo para comparar imagenes, sin embargo, al pasar estas imagenes por una red convolucional pre entrenada i.e. VGG, las features resultantes poseen una alta coherencia semantica, lo cual los hace buenos candidatos para comparar imagenes perceptualmente. En consecuencia, es posible construir un algoritmo de optimizacion en el cual se busque el vector latente que generó dicha imagen.\n",
    "\n",
    "\n",
    "La implementacion oficial de stylegan posee un archivo llamado [`run_projection.sh`](https://github.com/NVlabs/stylegan2/blob/master/run_projector.py), es un poquito tricky hackearla, así que me hice mi propio script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhyjZ_Ovz92y",
    "outputId": "81966337-4562-472a-9eb8-b44b465a28fd"
   },
   "outputs": [],
   "source": [
    "!python project_images.py --num-steps 500 aligned generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvHw35u5CwvC"
   },
   "source": [
    "Ok... ¿Entonces en teoria si pasamos esa imagen por stylegan deberíamos obtener una imagen parecida la de entrada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "lLjAwzXQEqBV",
    "outputId": "ff369912-01ce-42a9-b41e-14ff3579d350"
   },
   "outputs": [],
   "source": [
    "display_images(\n",
    "    [Image.open('aligned/alejo_01.jpeg.png'), Image.open('generated/alejo_01.jpeg.png')],\n",
    "    columns=2,\n",
    "    width=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pBhrLwJE2da"
   },
   "source": [
    "Vale, parece funcionar. Ahora ¿Como transferimos el estilo? Simple! la respusta está en el fine-tuning. Tipicamente cuando se fine tunea un modelo, se congelan las primeras capaz de la red y se tunean las ultimas. Esto se debe a que las primeras capaz suelen aprender features mas generales. Ahora esto tambien aplica en StyleGAN peeero, teniendo en cuenta, que este fue entrenado progresivamente, las primeras capaz (las cuales, condicionan las posteriores) fueron entrenadas para ser capaces la imagen, pero con una menor resolucion. Al fine tunear StyleGAN se observa una propiedad muy interesante y es que existe una consistencia entre los estilos del modelo inicial y el fine tuneado. En otras palabras, teniendo en cuenta que las primeras capaz generaran una version en baja resolucion de la imagen que esperamos. Las intermedias trataran de agregar mas resolucion e informacion a la imagen. Un modelo tuneado de stylegan en estas capaz intermedias no solo aumenta la resolucion sino que trata de afinar el estilo (pues para esto fue entrenado). \n",
    "\n",
    "En particular, utilicé los pesos entrenados por [@ak92501](https://twitter.com/ak92501/status/1282466682267676675?s=20). El utilizo MetFaces a una resloucion de 1024x1024 usando como base la configuracion f de stylegan2. \n",
    "\n",
    "Al realizar esto, se espera encontrar una version \"pintada\" de la cara de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsP48cLpEDOh",
    "outputId": "faf88931-6870-49c8-beb8-33d62b5d07e8"
   },
   "outputs": [],
   "source": [
    "import pretrained_networks\n",
    "\n",
    "metfaces = 'https://drive.google.com/uc?id=1H-MYFZqngF1R0whm4bc3fEoX7VvOWaDl'\n",
    "ffhq = 'http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl'\n",
    "\n",
    "_, _, Gs_blended = pretrained_networks.load_networks(metfaces)\n",
    "_, _, Gs = pretrained_networks.load_networks(ffhq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJReLjvMG2Y5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "from pathlib import Path\n",
    "\n",
    "latent_dir = Path(\"generated\")\n",
    "latents = latent_dir.glob(\"*.npy\")\n",
    "for latent_file in latents:\n",
    "  latent = np.load(latent_file)\n",
    "  latent = np.expand_dims(latent,axis=0)\n",
    "  synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
    "  images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\n",
    "  Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').save(latent_file.parent / (f\"{latent_file.stem}-art.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "4fKgCIhLG_uM",
    "outputId": "39e8d664-1d8e-4e4a-bac1-e267d05b1676"
   },
   "outputs": [],
   "source": [
    "display_images(\n",
    "    [Image.open('generated/alejo_01.jpeg.png'), Image.open('generated/alejo_01.jpeg-art.jpg')],\n",
    "    columns=2,\n",
    "    width=8,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
